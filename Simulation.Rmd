---
title: "Simulation Code"
output: pdf_document
date: "2024-03-06"
---

```{r message=FALSE}
library(MASS)
library(tidyverse)
library(caret)
library(class)
library(rpart)
library(randomForest)

set.seed(0)
```

# Mini simulation to test the p and $\beta_0$ relationship formula

```{r}
# p and beta 0 relationship Monte Carlo test
n_test <- 10^6
desired_p <- c(0.05, 0.25, 0.5, 0.75, 0.95)

sigmoid <- function(x) {
  return (1 / (1+exp(-x)))
}

get_beta0 <- function(beta1, beta2) {
  
  # grid of beta 0 to try
  beta0_vec <- seq(-10, 10, 0.1) 
  
  # placeholder p vector
  ps <- rep(NA, length(beta0_vec))
  
  # get empircal proportion for each beta0
  for (i in 1:length(beta0_vec)) {
    X1 <- rnorm(n, 0, 2)
    X2 <- rexp(n, 0.5) - 2
    
    probs <- sigmoid(beta0_vec[i] + beta1 * X1 + beta2 * X2)
    
    Y <- rbinom(n, 1, probs)
    
    ps[i] <- mean(Y)
  }
  
  final_beta0 <- rep(NA, length(desired_p))
  
  # find best beta0 for each desired p
  for (i in 1:length(desired_p)) {
    final_beta0[i] <- beta0_vec[which.min(abs(ps - desired_p[i]))]
  }
  
  return (final_beta0)
}

case1_beta0s <- get_beta0(0.5, 0.5)
case2_beta0s <- get_beta0(2, 2)
case3_beta0s <- get_beta0(2, 0)
case4_beta0s <- get_beta0(0, 2)

case1_beta0s
case2_beta0s
case3_beta0s
case4_beta0s
```


# Data Generation

```{r}
generate_data <- function(n, beta_0, beta_1, beta_2) {
  X1 <- rnorm(n, mean = 0, sd = 2)
  X2 <- rexp(n, rate = 0.5) - 2
  linear_combination <- beta_0 + beta_1 * X1 + beta_2 * X2
  prob <- exp(linear_combination) / (1 + exp(linear_combination))
  Y <- rbinom(n, size = 1, prob = prob)
  data <- data.frame(Y, X1, X2)
  return(data)
}
```

```{r eval=FALSE}
n_iter <- 1000
h <- 2000

for (iter in 1:1000) {
  for (i in 1:length(desired_p)) {
    data <- generate_data(n, case1_beta0s[i], 0.5, 0.5)
    write.csv(data, file.path("data/", sprintf("data_case%s_p%s_iter%s.csv", 1, desired_p[i], iter)), 
              row.names = FALSE)
  }
  
  for (i in 1:length(desired_p)) {
    data <- generate_data(n, case2_beta0s[i], 2, 2)
    write.csv(data, file.path("data/", sprintf("data_case%s_p%s_iter%s.csv", 2, desired_p[i], iter)), 
              row.names = FALSE)
  }
  
  for (i in 1:length(desired_p)) {
    data <- generate_data(n, case3_beta0s[i], 2, 0)
    write.csv(data, file.path("data/", sprintf("data_case%s_p%s_iter%s.csv", 3, desired_p[i], iter)),
              row.names = FALSE)
  }
  
  for (i in 1:length(desired_p)) {
    data <- generate_data(n, case4_beta0s[i], 0, 2)
    write.csv(data, file.path("data/", sprintf("data_case%s_p%s_iter%s.csv", 4, desired_p[i], iter)),
              row.names = FALSE)
  } 
}
```


# Fitting Models

## Train-test split

```{r}
# get indices stratifying by class
train_idx <- createDataPartition(data$Y, p=0.7, list=FALSE)

# split the data
train_data <- data[train_idx,]
test_data <- data[-train_idx,]
```

## Logistic Regression

```{r}
# fit the model
logit <- glm(Y~X1 + X2,
             data=train_data, family="binomial")
```

## KNN

```{r}
train_scaled <- data.frame(X1_scaled = scale(train_data$X1), 
                           X2_scaled = scale(train_data$X2), 
                           Y = train_data$Y)

test_scaled <- data.frame(X1_scaled = scale(test_data$X1), 
                           X2_scaled = scale(test_data$X2), 
                           Y = test_data$Y)

cvIndex <- createFolds(factor(train_scaled$Y), 5, returnTrain=T)
train_control <- trainControl(index=cvIndex,
                              method="cv",
                              number=5)

knn_CV <- train(factor(Y)~X1_scaled+X2_scaled,
      data=train_scaled,
      method="knn",
      trControl = train_control,
      tuneGrid = data.frame(k = seq(5, 50, 5)))

final_knn <- knn3(factor(Y)~X1_scaled+X2_scaled,
                 data=train_scaled,
                 k = knn_CV$bestTune$k)
```

## Decision Trees

```{r}
# Decision Trees
cvIndex <- createFolds(factor(train_data$Y), 5, returnTrain=T)
train_control <- trainControl(index=cvIndex,
                              method="cv",
                              number=5)

validatedTree <- train(factor(Y)~X1+X2,
              data=train_data,
              method="rpart",
              trControl=train_control,
              tuneLength=10)

finalTree <- rpart(factor(Y)~X1+X2, data=train_data, control=list(cp=validatedTree$bestTune$cp))
```

## Random Forest

```{r}
cvIndex <- createFolds(factor(train_data$Y), 5, returnTrain=T)
train_control <- trainControl(index=cvIndex,
                              method="cv",
                              number=5,
                              search="grid")

forest_cv <- train(factor(Y)~X1+X2,
              data=train_data,
              method="rf",
              trControl=train_control,
              tuneGrid=expand.grid(mtry=c(1,2)),
              ntree=100)

finalForest <- randomForest(factor(Y)~X1+X2,
                            data=train_data,
                            ntree=100,
                            mtry=forest_cv$bestTune$mtry)
```


# Evaluation on Unbalanced Data

## Accuracy

```{r}
# Logistic Regression
get_logit_preds <- function(model, data) {
  yhat <- predict(model, new=data)
  phat <- exp(yhat) / (1+exp(yhat))
  preds <- round(phat)
  return (preds)
}

train_logit_preds <- get_logit_preds(logit, train_data)
mean(train_logit_preds == train_data$Y)

test_logit_preds <- get_logit_preds(logit, test_data)
mean(test_logit_preds == test_data$Y)
```

```{r}
# knn
train_knn_preds <- predict(final_knn, newdata=train_scaled, type="class")
mean(train_knn_preds == train_scaled$Y)

test_knn_preds <- predict(final_knn, newdata=test_scaled, type="class")
mean(test_knn_preds == test_scaled$Y)
```


```{r}
# Decision Trees
train_tree_preds <- predict(finalTree, newdata = train_data, type="class")
mean(train_tree_preds == train_data$Y)

test_tree_preds <- predict(finalTree, newdata = test_data, type="class")
mean(test_tree_preds == test_data$Y)
```

```{r}
# Random Forest
train_forest_preds <- predict(finalForest, newdata=train_data, type="class")
mean(train_forest_preds == train_data$Y)

test_forest_preds <- predict(finalForest, newdata = test_data, type="class")
mean(test_forest_preds == test_data$Y)
```


## Confusion Matrices

```{r}
# Logistic Regression Train
logit_cm_train <- confusionMatrix(factor(train_logit_preds), factor(train_data$Y))
logit_cm_train$table
logit_cm_train$byClass
```

```{r}
# Logistic Regression Test
logit_cm_test <- confusionMatrix(factor(test_logit_preds), factor(test_data$Y))
logit_cm_test$table
logit_cm_test$byClass
```

```{r}
#knn train
knn_cm_train <- confusionMatrix(factor(train_knn_preds), factor(train_data$Y))
knn_cm_train$table
knn_cm_train$byClass
```

```{r}
#knn test
knn_cm_test <- confusionMatrix(factor(test_knn_preds), factor(test_data$Y))
knn_cm_test$table
knn_cm_test$byClass
```


```{r}
# Decision Tree Train
tree_cm_train <- confusionMatrix(factor(train_tree_preds), factor(train_data$Y))
tree_cm_train$table
tree_cm_train$byClass
```

```{r}
# Decision Tree Test
tree_cm_test <- confusionMatrix(factor(test_tree_preds), factor(test_data$Y))
tree_cm_test$table
tree_cm_test$byClass
```

```{r}
# Random forest train
forest_cm_train <- confusionMatrix(factor(train_forest_preds), factor(train_data$Y))
forest_cm_train$table
forest_cm_train$byClass
```

```{r}
#random forest test
forest_cm_test <- confusionMatrix(factor(test_forest_preds), factor(test_data$Y))
forest_cm_test$table
forest_cm_test$byClass
```
{r}
library(ROSE)
library(themis)
library(tidymodels)
library(caret)

# Function to perform oversampling on the training data
oversample_data <- function(train_data) {
  # Directly specify N within the ovun.sample call
  oversampled_data <- ovun.sample(Y ~ ., data = train_data, method = "over", 
                                  N = table(train_data$Y)[1] + 2*table(train_data$Y)[2])$data
  return(oversampled_data)
}



# Adjusted Function to perform undersampling on the training data
undersample_data <- function(train_data) {
  # Calculate N_size directly within the ovun.sample call
  undersampled_data <- ovun.sample(Y ~ ., data = train_data, method = "under", 
                                   N = 2 * min(table(train_data$Y)))$data
  return(undersampled_data)
}



# Function to perform SMOTE on the training data, ensuring Y is a factor
smote_data <- function(train_data) {
  # Convert Y to a factor if it's not already
  train_data$Y <- as.factor(train_data$Y)

  # Create a recipe with Y as a factor
  rec <- recipe(Y ~ ., data = train_data) %>%
    step_smote(Y)

  # Prepare the recipe with training data
  prep_rec <- prep(rec, training = train_data)

  # Bake the recipe to apply transformations
  smoted_data <- bake(prep_rec, new_data = NULL)

  return(smoted_data)
}


# Apply the resampling techniques to the training data
for (file in list.files("data/")) {
  # Read the dataset
  data_path <- file.path("data", file)
  data <- read.csv(data_path)
  
  # Split into train and test sets
  set.seed(0)
  train_idx <- createDataPartition(data$Y, p = 0.7, list = FALSE)
  train_data <- data[train_idx, ]
  test_data <- data[-train_idx, ]
  
  # Apply oversampling
  oversampled_train_data <- oversample_data(train_data)
  
  # Apply undersampling
  undersampled_train_data <- undersample_data(train_data)
  
  # Apply SMOTE
  smote_train_data <- smote_data(train_data)
  
  # Now you can proceed to fit your models on these balanced datasets
  # Example: Fit a logistic regression model on the oversampled data
  # logit_model_oversampled <- glm(Y ~ ., data = oversampled_train_data, family = binomial())
  
  # Repeat model fitting for undersampled and SMOTE data as needed
  # Save or evaluate the models as per your research plan
}
